{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b9b7f2-3082-463e-b79a-d53d5afedd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: discomfort\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Function to load a model or other objects from a file\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "trained_model = load_pickle('../notebooks/models/audio_augmented_model/svm_model.pkl')\n",
    "scaler = load_pickle('../notebooks/models/audio_augmented_model/scaler_svm.pkl')\n",
    "label_encoder = load_pickle('../notebooks/models/audio_augmented_model/label_encoder_svm.pkl')\n",
    "\n",
    "# Define a fixed length for MFCC feature vectors\n",
    "max_length = 100\n",
    "\n",
    "# Extract MFCC Features and Chop audio\n",
    "# Preemphasis filter for high frequency\n",
    "def preemphasis_filter(signal, alpha=0.97):\n",
    "    return np.append(signal[0], signal[1:] - alpha * signal[:-1])\n",
    "\n",
    "# Frame the signal into 25 ms frame and 10 ms frame shift\n",
    "def frame_signal(signal, frame_length, frame_stride):\n",
    "    signal_length = len(signal)\n",
    "    frame_step = int(frame_stride)\n",
    "    frame_length = int(frame_length)\n",
    "    num_frames = int(np.ceil(float(np.abs(signal_length - frame_length)) / frame_step))\n",
    "\n",
    "    pad_signal_length = num_frames * frame_step + frame_length\n",
    "    z = np.zeros((pad_signal_length - signal_length))\n",
    "    pad_signal = np.append(signal, z)\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (num_frames, 1)) + \\\n",
    "              np.tile(np.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\n",
    "    frames = pad_signal[indices.astype(np.int32, copy=False)]\n",
    "\n",
    "    return frames\n",
    "    \n",
    "# Apply Hamming Windows and Compute the power spectrum\n",
    "def power_spectrum(frames, NFFT=512):\n",
    "    frames *= np.hamming(frames.shape[1])\n",
    "    mag_frames = np.absolute(np.fft.rfft(frames, NFFT))\n",
    "    pow_frames = ((1.0 / NFFT) * (mag_frames ** 2))\n",
    "    return pow_frames\n",
    "\n",
    "# Apply Mel Filterbank\n",
    "def mel_filterbank(spectrum, num_filters=40, sampling_rate=22050, n_fft=512):\n",
    "    mel_filterbank = librosa.filters.mel(sr=sampling_rate, n_fft=n_fft, n_mels=num_filters)\n",
    "    return np.dot(mel_filterbank, spectrum.T).T\n",
    "\n",
    "# Compute MFCCS\n",
    "def mfcc(signal, sampling_rate=22050, frame_length=512, frame_shift=256, num_mfcc=13, n_mels=40):\n",
    "    emphasized_signal = preemphasis_filter(signal)\n",
    "    framed_signal = frame_signal(emphasized_signal, frame_length, frame_shift)\n",
    "    spectrum = power_spectrum(framed_signal)\n",
    "    mel_spectrum = mel_filterbank(spectrum, num_filters=n_mels, sampling_rate=sampling_rate, n_fft=512)\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(mel_spectrum), n_mfcc=num_mfcc, n_mels=n_mels)\n",
    "\n",
    "    return mfccs\n",
    "# Function to preprocess audio files using your provided code\n",
    "def preprocess_audio(audio_path):\n",
    "    audiofile, sr = librosa.load(audio_path, sr=None)\n",
    "    mfcc_features = mfcc(audiofile, sr)\n",
    "    if mfcc_features.shape[1] < max_length:\n",
    "        mfcc_features_padded = np.pad(mfcc_features, ((0, 0), (0, max_length - mfcc_features.shape[1])), mode='constant')\n",
    "    elif mfcc_features.shape[1] > max_length:\n",
    "        mfcc_features_padded = mfcc_features[:, :max_length]\n",
    "    else:\n",
    "        mfcc_features_padded = mfcc_features\n",
    "    mfcc_features_flat = mfcc_features_padded.flatten()\n",
    "    mfcc_features_flat = scaler.transform([mfcc_features_flat])\n",
    "    return mfcc_features_flat\n",
    "\n",
    "# Function to make predictions on preprocessed audio\n",
    "def predict_audio(preprocessed_audio):\n",
    "    prediction = trained_model.predict(preprocessed_audio)\n",
    "    predicted_label = label_encoder.inverse_transform(prediction)[0]\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "audio_path = '../data/indiv_test/435806317_25534324009486266_6473560724221715299_n.wav'  # Replace with your audio file path\n",
    "preprocessed_audio = preprocess_audio(audio_path)\n",
    "predicted_label = predict_audio(preprocessed_audio)\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
