{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e987644f-1671-4a8e-a163-56685e06ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c5d9dc5-bfa0-4687-8c55-127855209435",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Audio File -> reading the melspectogram and cqt -> 'di pa actual na processing, more on training phase\n",
    "\n",
    "def preprocess_audio_path(audio_file_path, \n",
    "                          melspect_output_path, \n",
    "                          cqt_output_path, sr=22050, \n",
    "                          n_fft=2048, hop_length=512, \n",
    "                          n_mels=128, batch_size=10):\n",
    "\n",
    "    for root, dirs, files in os.walk(audio_file_path):\n",
    "        for dir in dirs:\n",
    "            input_dir = os.path.join(root, dir)\n",
    "\n",
    "            for file_name in os.listdir(input_dir):\n",
    "                ### Need to implement try-catch here or other way to convert other .file extension to .wav\n",
    "                if file_name.endswith('.wav'):\n",
    "                    print(\"Processing File:\", file_name)\n",
    "                    mel_output_dir = os.path.join(melspect_output_path, dir)\n",
    "                    cqt_output_dir = os.path.join(cqt_output_path, dir)\n",
    "                    os.makedirs(mel_output_dir, exist_ok=True)\n",
    "                    os.makedirs(cqt_output_dir, exist_ok=True)\n",
    "\n",
    "                    ### Load the audio file\n",
    "                    file_path = os.path.join(input_dir, file_name)\n",
    "                    audio, _ = librosa.load(file_path, sr=sr)\n",
    "\n",
    "                    ### Check if the audio is not mono\n",
    "                    if len(audio.shape) > 1 and audio.shape[0] == 2:\n",
    "                        audio = librosa.to_mono(audio)\n",
    "\n",
    "                    ### Normalize the audio this is optional\n",
    "                    normalized_audio = librosa.util.normalize(audio)\n",
    "\n",
    "                    # Compute Mel Spectogram\n",
    "                    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "                    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "                    # Compute CQT Spectegoram\n",
    "                    cqt_spec = librosa.cqt(audio, sr=sr, hop_length=hop_length)\n",
    "                    cqt_mag_spec = np.abs(cqt_spec)\n",
    "                    cqt_mag_spec_db = librosa.amplitude_to_db(cqt_mag_spec, ref=np.max)\n",
    "\n",
    "                    # Save Mel Spectogram as PNG Image to Mel output folder\n",
    "                    mel_output_file_path = os.path.join(mel_output_dir, file_name.replace('.wav', '_mel.png'))\n",
    "                    plt.figure(figsize=(10,4))\n",
    "                    librosa.display.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel')\n",
    "                    plt.colorbar(format='%+2.0f dB')\n",
    "                    plt.savefig(mel_output_file_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                    # Save CQT \n",
    "                    cqt_output_file_path = os.path.join(cqt_output_dir, file_name.replace('.wav', '_cqt.png'))\n",
    "                    plt.figure(figsize=(10,4))\n",
    "                    librosa.display.specshow(cqt_mag_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='cqt_note')\n",
    "                    plt.colorbar(format='%+2.0f dB')\n",
    "                    plt.savefig(cqt_output_file_path, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                    del audio, mel_spec, mel_spec_db, cqt_spec, cqt_mag_spec, cqt_mag_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236d947-0d05-46f2-96ca-42f05b682765",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder_path = '../data/raw/'\n",
    "melspect_output_path = '../data/raw/Mel Feature'\n",
    "cqt_output_path = '../data/raw/CQT Spect'\n",
    "\n",
    "preprocess_audio_path(audio_file_path=audio_folder_path, melspect_output_path=melspect_output_path, cqt_output_path=cqt_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f17dbe5-3346-4a78-adee-46fbf3778b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw/burping\n",
      "../data/raw/hungry\n",
      "../data/raw/belly_pain\n",
      "../data/raw/discomfort\n",
      "../data/raw/tired\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('../data/raw/'):\n",
    "    for dir in dirs:\n",
    "        input_dir = os.path.join(root, dir)\n",
    "        print(input_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
